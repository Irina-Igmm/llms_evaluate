{"spans": [{"name": "VectorStoreRetriever", "context": {"span_id": "0xb363400e6ebb0aec", "trace_id": "0x57eb7eec39c2dfe8f62d789473313960"}, "parent_id": null, "start_time": 1729780071324004200, "end_time": 1729780071798076400, "status_code": "OK", "status_message": "", "attributes": {"mlflow.traceRequestId": "\"d7ef2fd03b914a81b2fd963974ee65c3\"", "mlflow.spanType": "\"RETRIEVER\"", "mlflow.spanInputs": "\"Donne-moi un exemple de données synthétiques textuelles.\"", "mlflow.spanOutputs": "[{\"page_content\": \"Une fausse photo du jeune Elon Musk jouant au jeu vidéo Mars Marauder en 1995, générée par l'IA Des réseaux antagonistes génératifs ont parfois été utilisés pour créer de fausses images réalistes, comme avec le générateur de visages StyleGAN introduit en 2018[120], ou avec « Terre Seconde » de Grégory Chatonsky qui imagine en 2019 une version alternative de la planète Terre[121].\\nDès 2022 apparaissent des modèles d'intelligence artificielle qui sont capables de créer des images réalistes à partir de descriptions textuelles, comme Midjourney, Stable Diffussion et DALL-E[122],[123]. En mars 2023, des fausses photos d'actualité sont ainsi générées et diffusées sur Internet, mettant en scène des personnalités dans des situations extravagantes (le président Macron ramassant des poubelles, Donald Trump arrêté par des policiers[124], le pape François habillé en doudoune blanche[125]). Elles deviennent rapidement virales, augmentant les craintes de manipulation de l'opinion[126]. Cela pose aussi des questions de droits d'auteur[127].\", \"metadata\": {\"language\": \"fr\", \"source\": \"https://fr.wikipedia.org/wiki/Intelligence_artificielle\", \"title\": \"Intelligence artificielle — Wikipédia\"}, \"id\": null}, {\"page_content\": \"Une fausse photo du jeune Elon Musk jouant au jeu vidéo Mars Marauder en 1995, générée par l'IA Des réseaux antagonistes génératifs ont parfois été utilisés pour créer de fausses images réalistes, comme avec le générateur de visages StyleGAN introduit en 2018[120], ou avec « Terre Seconde » de Grégory Chatonsky qui imagine en 2019 une version alternative de la planète Terre[121].\\nDès 2022 apparaissent des modèles d'intelligence artificielle qui sont capables de créer des images réalistes à partir de descriptions textuelles, comme Midjourney, Stable Diffussion et DALL-E[122],[123]. En mars 2023, des fausses photos d'actualité sont ainsi générées et diffusées sur Internet, mettant en scène des personnalités dans des situations extravagantes (le président Macron ramassant des poubelles, Donald Trump arrêté par des policiers[124], le pape François habillé en doudoune blanche[125]). Elles deviennent rapidement virales, augmentant les craintes de manipulation de l'opinion[126]. Cela pose aussi des questions de droits d'auteur[127].\", \"metadata\": {\"language\": \"fr\", \"source\": \"https://fr.wikipedia.org/wiki/Intelligence_artificielle\", \"title\": \"Intelligence artificielle — Wikipédia\"}, \"id\": null}, {\"page_content\": \"Une fausse photo du jeune Elon Musk jouant au jeu vidéo Mars Marauder en 1995, générée par l'IA Des réseaux antagonistes génératifs ont parfois été utilisés pour créer de fausses images réalistes, comme avec le générateur de visages StyleGAN introduit en 2018[120], ou avec « Terre Seconde » de Grégory Chatonsky qui imagine en 2019 une version alternative de la planète Terre[121].\\nDès 2022 apparaissent des modèles d'intelligence artificielle qui sont capables de créer des images réalistes à partir de descriptions textuelles, comme Midjourney, Stable Diffussion et DALL-E[122],[123]. En mars 2023, des fausses photos d'actualité sont ainsi générées et diffusées sur Internet, mettant en scène des personnalités dans des situations extravagantes (le président Macron ramassant des poubelles, Donald Trump arrêté par des policiers[124], le pape François habillé en doudoune blanche[125]). Elles deviennent rapidement virales, augmentant les craintes de manipulation de l'opinion[126]. Cela pose aussi des questions de droits d'auteur[127].\", \"metadata\": {\"language\": \"fr\", \"source\": \"https://fr.wikipedia.org/wiki/Intelligence_artificielle\", \"title\": \"Intelligence artificielle — Wikipédia\"}, \"id\": null}, {\"page_content\": \"Grands modèles de langages[modifier | modifier le code]\\nLes grands modèles de langage sont des modèles de langage ayant un grand nombre de paramètres, typiquement des milliards. Ils reposent très souvent sur l'architecture transformeur[23].\\nLes transformeurs génératifs pré-entraînés (Generative Pretrained Transformers ou GPT en anglais) sont un type particulièrement populaire de grand modèle de langage. Leur « pré-entraînement » consiste à prédire, étant donnée une partie d'un texte, le token suivant (un token étant une séquence de caractères, typiquement un mot, une partie d'un mot, ou de la ponctuation). Cet entraînement à prédire ce qui va suivre, répété pour un grand nombre de textes, permet à ces modèles d'accumuler des connaissances sur le monde. Ils peuvent ensuite générer du texte semblable à celui ayant servi au pré-entraînement, en prédisant un à un les tokens suivants. En général, une autre phase d'entraînement est ensuite effectuée pour rendre le modèle plus véridique, utile et inoffensif. Cette phase d'entraînement (utilisant souvent une technique appelée RLHF) permet notamment de réduire un phénomène appelé « hallucination », où le modèle génère des informations d'apparence plausible mais fausses[24].\\nAvant d'être fourni au modèle, le texte est découpé en tokens. Ceux-ci sont convertis en vecteurs qui en encodent le sens ainsi que la position dans le texte. À l'intérieur de ces modèles se trouve une alternance de réseaux de neurones et de couches d'attention. Les couches d'attention combinent les concepts entre eux, permettant de tenir compte du contexte et de saisir des relations complexes[25].\\nCes modèles sont souvent intégrés dans des agents conversationnels, aussi appelés chatbots, où le texte généré est formaté pour répondre à l'utilisateur. Par exemple, l'agent conversationnel ChatGPT exploite les modèles GPT-3.5 et GPT-4[26]. En 2023 font leur apparition des modèles grand public pouvant traiter simultanément différents types de données comme le texte, le son, les images et les vidéos, tel Google Gemini[27].\", \"metadata\": {\"language\": \"fr\", \"source\": \"https://fr.wikipedia.org/wiki/Intelligence_artificielle\", \"title\": \"Intelligence artificielle — Wikipédia\"}, \"id\": null}, {\"page_content\": \"Grands modèles de langages[modifier | modifier le code]\\nLes grands modèles de langage sont des modèles de langage ayant un grand nombre de paramètres, typiquement des milliards. Ils reposent très souvent sur l'architecture transformeur[23].\\nLes transformeurs génératifs pré-entraînés (Generative Pretrained Transformers ou GPT en anglais) sont un type particulièrement populaire de grand modèle de langage. Leur « pré-entraînement » consiste à prédire, étant donnée une partie d'un texte, le token suivant (un token étant une séquence de caractères, typiquement un mot, une partie d'un mot, ou de la ponctuation). Cet entraînement à prédire ce qui va suivre, répété pour un grand nombre de textes, permet à ces modèles d'accumuler des connaissances sur le monde. Ils peuvent ensuite générer du texte semblable à celui ayant servi au pré-entraînement, en prédisant un à un les tokens suivants. En général, une autre phase d'entraînement est ensuite effectuée pour rendre le modèle plus véridique, utile et inoffensif. Cette phase d'entraînement (utilisant souvent une technique appelée RLHF) permet notamment de réduire un phénomène appelé « hallucination », où le modèle génère des informations d'apparence plausible mais fausses[24].\\nAvant d'être fourni au modèle, le texte est découpé en tokens. Ceux-ci sont convertis en vecteurs qui en encodent le sens ainsi que la position dans le texte. À l'intérieur de ces modèles se trouve une alternance de réseaux de neurones et de couches d'attention. Les couches d'attention combinent les concepts entre eux, permettant de tenir compte du contexte et de saisir des relations complexes[25].\\nCes modèles sont souvent intégrés dans des agents conversationnels, aussi appelés chatbots, où le texte généré est formaté pour répondre à l'utilisateur. Par exemple, l'agent conversationnel ChatGPT exploite les modèles GPT-3.5 et GPT-4[26]. En 2023 font leur apparition des modèles grand public pouvant traiter simultanément différents types de données comme le texte, le son, les images et les vidéos, tel Google Gemini[27].\", \"metadata\": {\"language\": \"fr\", \"source\": \"https://fr.wikipedia.org/wiki/Intelligence_artificielle\", \"title\": \"Intelligence artificielle — Wikipédia\"}, \"id\": null}]"}, "events": []}], "request": "\"Donne-moi un exemple de données synthétiques textuelles.\"", "response": "[{\"page_content\": \"Une fausse photo du jeune Elon Musk jouant au jeu vidéo Mars Marauder en 1995, générée par l'IA Des réseaux antagonistes génératifs ont parfois été utilisés pour créer de fausses images réalistes, comme avec le générateur de visages StyleGAN introduit en 2018[120], ou avec « Terre Seconde » de Grégory Chatonsky qui imagine en 2019 une version alternative de la planète Terre[121].\\nDès 2022 apparaissent des modèles d'intelligence artificielle qui sont capables de créer des images réalistes à partir de descriptions textuelles, comme Midjourney, Stable Diffussion et DALL-E[122],[123]. En mars 2023, des fausses photos d'actualité sont ainsi générées et diffusées sur Internet, mettant en scène des personnalités dans des situations extravagantes (le président Macron ramassant des poubelles, Donald Trump arrêté par des policiers[124], le pape François habillé en doudoune blanche[125]). Elles deviennent rapidement virales, augmentant les craintes de manipulation de l'opinion[126]. Cela pose aussi des questions de droits d'auteur[127].\", \"metadata\": {\"language\": \"fr\", \"source\": \"https://fr.wikipedia.org/wiki/Intelligence_artificielle\", \"title\": \"Intelligence artificielle — Wikipédia\"}, \"id\": null}, {\"page_content\": \"Une fausse photo du jeune Elon Musk jouant au jeu vidéo Mars Marauder en 1995, générée par l'IA Des réseaux antagonistes génératifs ont parfois été utilisés pour créer de fausses images réalistes, comme avec le générateur de visages StyleGAN introduit en 2018[120], ou avec « Terre Seconde » de Grégory Chatonsky qui imagine en 2019 une version alternative de la planète Terre[121].\\nDès 2022 apparaissent des modèles d'intelligence artificielle qui sont capables de créer des images réalistes à partir de descriptions textuelles, comme Midjourney, Stable Diffussion et DALL-E[122],[123]. En mars 2023, des fausses photos d'actualité sont ainsi générées et diffusées sur Internet, mettant en scène des personnalités dans des situations extravagantes (le président Macron ramassant des poubelles, Donald Trump arrêté par des policiers[124], le pape François habillé en doudoune blanche[125]). Elles deviennent rapidement virales, augmentant les craintes de manipulation de l'opinion[126]. Cela pose aussi des questions de droits d'auteur[127].\", \"metadata\": {\"language\": \"fr\", \"source\": \"https://fr.wikipedia.org/wiki/Intelligence_artificielle\", \"title\": \"Intelligence artificielle — Wikipédia\"}, \"id\": null}, {\"page_content\": \"Une fausse photo du jeune Elon Musk jouant au jeu vidéo Mars Marauder en 1995, générée par l'IA Des réseaux antagonistes génératifs ont parfois été utilisés pour créer de fausses images réalistes, comme avec le générateur de visages StyleGAN introduit en 2018[120], ou avec « Terre Seconde » de Grégory Chatonsky qui imagine en 2019 une version alternative de la planète Terre[121].\\nDès 2022 apparaissent des modèles d'intelligence artificielle qui sont capables de créer des images réalistes à partir de descriptions textuelles, comme Midjourney, Stable Diffussion et DALL-E[122],[123]. En mars 2023, des fausses photos d'actualité sont ainsi générées et diffusées sur Internet, mettant en scène des personnalités dans des situations extravagantes (le président Macron ramassant des poubelles, Donald Trump arrêté par des policiers[124], le pape François habillé en doudoune blanche[125]). Elles deviennent rapidement virales, augmentant les craintes de manipulation de l'opinion[126]. Cela pose aussi des questions de droits d'auteur[127].\", \"metadata\": {\"language\": \"fr\", \"source\": \"https://fr.wikipedia.org/wiki/Intelligence_artificielle\", \"title\": \"Intelligence artificielle — Wikipédia\"}, \"id\": null}, {\"page_content\": \"Grands modèles de langages[modifier | modifier le code]\\nLes grands modèles de langage sont des modèles de langage ayant un grand nombre de paramètres, typiquement des milliards. Ils reposent très souvent sur l'architecture transformeur[23].\\nLes transformeurs génératifs pré-entraînés (Generative Pretrained Transformers ou GPT en anglais) sont un type particulièrement populaire de grand modèle de langage. Leur « pré-entraînement » consiste à prédire, étant donnée une partie d'un texte, le token suivant (un token étant une séquence de caractères, typiquement un mot, une partie d'un mot, ou de la ponctuation). Cet entraînement à prédire ce qui va suivre, répété pour un grand nombre de textes, permet à ces modèles d'accumuler des connaissances sur le monde. Ils peuvent ensuite générer du texte semblable à celui ayant servi au pré-entraînement, en prédisant un à un les tokens suivants. En général, une autre phase d'entraînement est ensuite effectuée pour rendre le modèle plus véridique, utile et inoffensif. Cette phase d'entraînement (utilisant souvent une technique appelée RLHF) permet notamment de réduire un phénomène appelé « hallucination », où le modèle génère des informations d'apparence plausible mais fausses[24].\\nAvant d'être fourni au modèle, le texte est découpé en tokens. Ceux-ci sont convertis en vecteurs qui en encodent le sens ainsi que la position dans le texte. À l'intérieur de ces modèles se trouve une alternance de réseaux de neurones et de couches d'attention. Les couches d'attention combinent les concepts entre eux, permettant de tenir compte du contexte et de saisir des relations complexes[25].\\nCes modèles sont souvent intégrés dans des agents conversationnels, aussi appelés chatbots, où le texte généré est formaté pour répondre à l'utilisateur. Par exemple, l'agent conversationnel ChatGPT exploite les modèles GPT-3.5 et GPT-4[26]. En 2023 font leur apparition des modèles grand public pouvant traiter simultanément différents types de données comme le texte, le son, les images et les vidéos, tel Google Gemini[27].\", \"metadata\": {\"language\": \"fr\", \"source\": \"https://fr.wikipedia.org/wiki/Intelligence_artificielle\", \"title\": \"Intelligence artificielle — Wikipédia\"}, \"id\": null}, {\"page_content\": \"Grands modèles de langages[modifier | modifier le code]\\nLes grands modèles de langage sont des modèles de langage ayant un grand nombre de paramètres, typiquement des milliards. Ils reposent très souvent sur l'architecture transformeur[23].\\nLes transformeurs génératifs pré-entraînés (Generative Pretrained Transformers ou GPT en anglais) sont un type particulièrement populaire de grand modèle de langage. Leur « pré-entraînement » consiste à prédire, étant donnée une partie d'un texte, le token suivant (un token étant une séquence de caractères, typiquement un mot, une partie d'un mot, ou de la ponctuation). Cet entraînement à prédire ce qui va suivre, répété pour un grand nombre de textes, permet à ces modèles d'accumuler des connaissances sur le monde. Ils peuvent ensuite générer du texte semblable à celui ayant servi au pré-entraînement, en prédisant un à un les tokens suivants. En général, une autre phase d'entraînement est ensuite effectuée pour rendre le modèle plus véridique, utile et inoffensif. Cette phase d'entraînement (utilisant souvent une technique appelée RLHF) permet notamment de réduire un phénomène appelé « hallucination », où le modèle génère des informations d'apparence plausible mais fausses[24].\\nAvant d'être fourni au modèle, le texte est découpé en tokens. Ceux-ci sont convertis en vecteurs qui en encodent le sens ainsi que la position dans le texte. À l'intérieur de ces modèles se trouve une alternance de réseaux de neurones et de couches d'attention. Les couches d'attention combinent les concepts entre eux, permettant de tenir compte du contexte et de saisir des relations complexes[25].\\nCes modèles sont souvent intégrés dans des agents conversationnels, aussi appelés chatbots, où le texte généré est formaté pour répondre à l'utilisateur. Par exemple, l'agent conversationnel ChatGPT exploite les modèles GPT-3.5 et GPT-4[26]. En 2023 font leur apparition des modèles grand public pouvant traiter simultanément différents types de données comme le texte, le son, les images et les vidéos, tel Google Gemini[27].\", \"metadata\": {\"language\": \"fr\", \"source\": \"https://fr.wikipedia.org/wiki/Intelligence_artificielle\", \"title\": \"Intelligence artificielle — Wikipédia\"}, \"id\": null}]"}